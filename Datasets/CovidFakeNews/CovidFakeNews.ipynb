{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d13b885",
   "metadata": {},
   "source": [
    "# COVID-19 News Dataset\n",
    "#### 10k+ social media posts and articles on COVID-19 manually labelled as true or false by a team\n",
    "https://arxiv.org/abs/2011.03327"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c78424",
   "metadata": {},
   "source": [
    "### Necessery Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f13b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "pd.set_option('display.max_rows', 500, \"display.max_colwidth\", None)\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c93e7b",
   "metadata": {},
   "source": [
    "## 1. Loading the datasets and merging them into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0b9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size od dataset:  (10700, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>States reported 1121 deaths a small rise from last Tuesday. Southern states reported 640 of those deaths. https://t.co/YASGRTT4ux</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandemic as Excuse Not to Reuse Plastic Bag https://t.co/thF8GuNFPe #coronavirus #nashville</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testing laboratories in India and as on 25th August 2020 36827520 tests have been done : @ProfBhargava DG @ICMRDELHI #StaySafe #IndiaWillWin https://t.co/Yh3ZxknnhZ</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Populous states can generate large case counts but if you look at the new cases per million today 9 smaller states are showing more cases per million than California or Texas: AL AR ID KS KY LA MS NV and SC. https://t.co/1pYW6cWRaS</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                     tweet  \\\n",
       "0                                           The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.   \n",
       "1                                                                                                        States reported 1121 deaths a small rise from last Tuesday. Southern states reported 640 of those deaths. https://t.co/YASGRTT4ux   \n",
       "2                                                                                                      Politically Correct Woman (Almost) Uses Pandemic as Excuse Not to Reuse Plastic Bag https://t.co/thF8GuNFPe #coronavirus #nashville   \n",
       "3                             #IndiaFightsCorona: We have 1524 #COVID testing laboratories in India and as on 25th August 2020 36827520 tests have been done : @ProfBhargava DG @ICMRDELHI #StaySafe #IndiaWillWin https://t.co/Yh3ZxknnhZ   \n",
       "4  Populous states can generate large case counts but if you look at the new cases per million today 9 smaller states are showing more cases per million than California or Texas: AL AR ID KS KY LA MS NV and SC. https://t.co/1pYW6cWRaS   \n",
       "\n",
       "  label  \n",
       "0  real  \n",
       "1  real  \n",
       "2  fake  \n",
       "3  real  \n",
       "4  real  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COVID_df_1 = pd.read_csv('Initial_datasets/COVID_train.csv', usecols = ['tweet', 'label'], low_memory=False)\n",
    "COVID_df_2 = pd.read_csv('Initial_datasets/english_test_with_labels.csv', usecols = ['tweet', 'label'], low_memory=False)\n",
    "COVID_df_3 = pd.read_csv('Initial_datasets/Constraint_val.csv', usecols = ['tweet', 'label'], low_memory=False)\n",
    "\n",
    "COVID_df = pd.concat([COVID_df_1, COVID_df_2, COVID_df_3], ignore_index=True)\n",
    "print(\"size od dataset: \", COVID_df.shape)\n",
    "COVID_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056d490",
   "metadata": {},
   "source": [
    "## 2. Examining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(COVID_df, x='label').update_xaxes(categoryarray=['real', 'fake'])\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749306f",
   "metadata": {},
   "source": [
    "### 2.1 URLs, Hashtags and Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea34c5",
   "metadata": {},
   "source": [
    "#### Delete Links, Hashtags and @ (mentions) at the end of tweets:\n",
    "\n",
    "Many entries include not only the claim we are interested in but also links to some resources, mentions and hashtags. Big portions of those come at the end of the tweet so by deleting them, the claim is cleaned from unncessery characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3e536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_df['modified_tweet'] = COVID_df['tweet']\n",
    "\n",
    "# Keep deleting the last word of a tweet if it's a link, hashtag (#) or a mention (@). \n",
    "# This usually does not influence the claim\n",
    "stop = False\n",
    "while stop == False:\n",
    "    prev_tweets = COVID_df['modified_tweet'].copy(deep=True)\n",
    "    COVID_df['modified_tweet'] = np.where((COVID_df['modified_tweet'].str.lower().str.rsplit(' ', 1).str[1].str.contains('http') == True) | \n",
    "                                         (COVID_df['modified_tweet'].str.lower().str.rsplit(' ', 1).str[1].str.contains('#') == True) | \n",
    "                                         (COVID_df['modified_tweet'].str.lower().str.rsplit(' ', 1).str[1].str.contains('@') == True), \n",
    "                                         COVID_df['modified_tweet'].str.rsplit(' ', 1).str[0], COVID_df['modified_tweet']) \n",
    "\n",
    "    if prev_tweets.equals(COVID_df['modified_tweet']):\n",
    "        stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d6103",
   "metadata": {},
   "source": [
    "#### Delete remaining entries with mentions (@) and link\n",
    "These entries have mentions and links in the middle of the tweet, therefore there wouldn't be useful when training our model, as we assume the input won't include any arbitrary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63547294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# link in the middle or at the front: 167, delete\n",
    "COVID_df = COVID_df.drop(COVID_df.loc[COVID_df['modified_tweet'].str.lower().str.contains('http') == True].index)\n",
    "\n",
    "# mention (@) still in the modified_tweet: 1443, delete - hard to encode\n",
    "COVID_df = COVID_df.drop(COVID_df.loc[COVID_df['modified_tweet'].str.lower().str.contains('@') == True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9decc88",
   "metadata": {},
   "source": [
    "#### Examining remaining hashtags\n",
    "These entries have mentions and links in the middle of the tweet, therefore there wouldn't be useful when training our model, as we assume the input won't include any arbitrary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7916bf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replacing the most frequent #COVID19 hashtag to normal word before further analysis and formatting\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace('#COVID19 ','COVID-19 ')\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace('#COVID-19 ','COVID-19 ')\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace('#COVID_19 ','COVID-19 ')\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace('#COVID ','COVID-19 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6188d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the entries that include hashtags in the form of \"CoronaVirusUpdate\" i.e. \n",
    "# entries that have hashtags with multiple words chained together (around 800 rows)\n",
    "COVID_df = COVID_df.drop(COVID_df.loc[(COVID_df['modified_tweet'].str.contains(r'#[A-Z][a-z]+[A-Z]'))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61205f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping entries that have #COVID19 and other stuff attatched to it like #COVIDNigeria\n",
    "COVID_df = COVID_df.drop(COVID_df.loc[COVID_df['modified_tweet'].str.lower().str.contains('#covid19[^ ,?.-]')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0483c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping entries that have 1 or more hashtags at the beginning of the claim (80)\n",
    "COVID_df = COVID_df.drop(COVID_df.loc[COVID_df['modified_tweet'].str.match(r'#[a-zA-Z\\d]+ #*')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7970ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries with hashtag and \":\" 35 -> Drop the first word\n",
    "COVID_df['modified_tweet'] = np.where(COVID_df['modified_tweet'].str.match('#[a-zA-Z\\d]+:'), \n",
    "                                      COVID_df['modified_tweet'].str.split(' ', 1).str[1], \n",
    "                                      COVID_df['modified_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee72d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still 522 entries have # in them (middle of the sentence) -> Drop the #\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace('#','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144df0cd",
   "metadata": {},
   "source": [
    "### 2.2 Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88504d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removind duplicates (around 120)\n",
    "COVID_df = COVID_df.drop_duplicates(subset='modified_tweet', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd756cb",
   "metadata": {},
   "source": [
    "### 2.3 Other Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415baa6",
   "metadata": {},
   "source": [
    "#### &amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a471592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries containing '&amp' (300) -> Drop\n",
    "COVID_df = COVID_df.drop(COVID_df[COVID_df['modified_tweet'].str.contains('&amp')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6afe8eb",
   "metadata": {},
   "source": [
    "#### \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29ee845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets containing '\\n' (180) -> Drop \n",
    "COVID_df = COVID_df.drop(COVID_df[COVID_df['modified_tweet'].str.contains('\\n')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa2859d",
   "metadata": {},
   "source": [
    "#### &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fd0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets containing ' & ' -> Replace with ' and ' instead (25)\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace(' & ',' and ')\n",
    "# Drop the tweets that have no spacing around '&' (the rest)\n",
    "COVID_df = COVID_df.drop(COVID_df[COVID_df['modified_tweet'].str.contains('&')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad965288",
   "metadata": {},
   "source": [
    "#### ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69750fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tweets containing '; [a-z]' (42) -> Switch to '. [a-z]' \n",
    "COVID_df['modified_tweet'] = np.where(COVID_df['modified_tweet'].str.contains(r'; [a-z]+'), \n",
    "                                      COVID_df['modified_tweet'].str.replace('; ',', '), \n",
    "                                      COVID_df['modified_tweet'])\n",
    "\n",
    "\n",
    "# Tweets containing '; [A-Z]' (17) -> Switch to '. [A-Z]' \n",
    "COVID_df['modified_tweet'] = np.where(COVID_df['modified_tweet'].str.contains(r'; [A-Z]+'), \n",
    "                                      COVID_df['modified_tweet'].str.replace('; ','. '), \n",
    "                                      COVID_df['modified_tweet'])\n",
    "\n",
    "# Rest of the tweets containing ';' (mostly gibbrish) -> Drop\n",
    "COVID_df = COVID_df.drop(COVID_df[COVID_df['modified_tweet'].str.contains(';')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5205b",
   "metadata": {},
   "source": [
    "#### Last sentence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f3b2563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After out prevoious formatting we need to look at the end of the tweets\n",
    "\n",
    "# Tweets that end with : (500) -> Deleting the last sentence\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].str.replace(r\"(?<=[.!?])[^.!?]*?:\\s*$\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c05470",
   "metadata": {},
   "source": [
    "#### Non-ascii characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcce7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting non-ascii characters from the strings\n",
    "COVID_df['modified_tweet'] = COVID_df['modified_tweet'].astype(str).apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4a0b0",
   "metadata": {},
   "source": [
    "#### First character check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f4986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTENCE wirth unusual starting character (340):\n",
    "# - multiple starting with _\n",
    "# - multiple starting with ?\n",
    "COVID_df.loc[COVID_df['modified_tweet'].str.match(r'[^a-zA-Z0-9\"$]')].shape[0]\n",
    "\n",
    "COVID_df['modified_tweet'] = np.where(COVID_df['modified_tweet'].str.startswith('_'), \n",
    "                                      COVID_df['modified_tweet'].str.replace('_',''), \n",
    "                                      COVID_df['modified_tweet'])\n",
    "\n",
    "COVID_df['modified_tweet'] = np.where(COVID_df['modified_tweet'].str.startswith('?'), \n",
    "                                      COVID_df['modified_tweet'].str.replace(r'[?]+','', regex=True), \n",
    "                                      COVID_df['modified_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e182f2a",
   "metadata": {},
   "source": [
    "#### ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c11afca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 166 entries with '???' -> delete the ???\n",
    "COVID_df[COVID_df['modified_tweet'].str.lower().str.contains('??', regex=False)].head(100)\n",
    "\n",
    "COVID_df['modified_tweet'] = np.where(COVID_df['modified_tweet'].str.contains('???', regex=False), \n",
    "                                      COVID_df['modified_tweet'].str.replace('???', '', regex=False), \n",
    "                                      COVID_df['modified_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156365b",
   "metadata": {},
   "source": [
    "### 2.4 Sentence length\n",
    "There are two main reasons to use logarithmic scales in charts and graphs. The first is to respond to skewness towards large values; i.e., cases in which one or a few points are much larger than the bulk of the data. The second is to show percent change or multiplicative factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bca18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_df['tweet_count'] = COVID_df['modified_tweet'].str.len()\n",
    "\n",
    "fig = px.histogram(COVID_df, x='tweet_count') # With log scale to see a better distribution\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()\n",
    "\n",
    "# 6000 entries with modified_tweet character count less than 200\n",
    "# COVID_df = COVID_df[COVID_df['modified_tweet'].str.len() < 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15980e5b",
   "metadata": {},
   "source": [
    "### 2.5 True/Fake distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(COVID_df, x='label').update_xaxes(categoryarray=['real', 'fake'])\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()\n",
    "\n",
    "# Change the type to boolean type\n",
    "COVID_df['label'] = (COVID_df['label'] == 'real').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424779e",
   "metadata": {},
   "source": [
    "## 3. Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f928ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_df_final = COVID_df[['modified_tweet', 'label']]\n",
    "COVID_df_final.rename(columns = {'modified_tweet': 'claim', 'label': 'claim_veracity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5da31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_df_final.to_csv('CovidFakeNews_Final.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
