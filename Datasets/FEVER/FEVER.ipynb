{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ae69fe",
   "metadata": {},
   "source": [
    "# FEVER \n",
    "150k short factual statements from Wikipedia annotated by trained personel, with 3 levels of claim veracity: supported, disprovided and not enough information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3880c6",
   "metadata": {},
   "source": [
    "#### Necessery imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332b4e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import json\n",
    "pd.set_option('display.max_rows', 500, \"display.max_colwidth\", None)\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4aaf9c",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a05871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145449"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEVER_df = pd.read_json('Initial_datasets/FEVER_initial.jsonl', lines=True)\n",
    "FEVER_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308e131",
   "metadata": {},
   "source": [
    "## 2. Examining the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdec49",
   "metadata": {},
   "source": [
    "### 2.1 Dropping unnessery columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c99e9",
   "metadata": {},
   "source": [
    "- We don't need the id or the evidence so we can drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fd7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEVER_df = FEVER_df.drop(['id', 'evidence'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc2070",
   "metadata": {},
   "source": [
    "- We also don't need the rows with \"Not enough info\" as we want clear indiciation if a claim is true or false. This also means that the \"Not verifiable\" rows will be deleted as there is a one-to-one relationship between these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965b6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEVER_df = FEVER_df.drop(FEVER_df.loc[FEVER_df['label'].str.lower().str.contains('not enough info')].index)\n",
    "FEVER_df.loc[FEVER_df['verifiable'].str.lower().str.contains('not verifiable')].shape[0]\n",
    "\n",
    "# Every claim is now \"verifiable\" so we can drop this column too\n",
    "FEVER_df = FEVER_df.drop(['verifiable'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb7a42",
   "metadata": {},
   "source": [
    "### 2.2 Examining true/fake entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008c99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the type of the entry to boolean with 1 meaning TRUE and 0 meaning it's a FALSE claim\n",
    "conditions = [FEVER_df['label'].eq('SUPPORTS'),\n",
    "              FEVER_df['label'].eq('REFUTES')]\n",
    "choices = [1, 0]\n",
    "FEVER_df['claim_veracity'] = np.select(conditions, choices, default = FEVER_df['label'])\n",
    "FEVER_df = FEVER_df.drop(['label'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(FEVER_df, x='claim_veracity').update_xaxes(categoryarray=[1, 0])\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10520e",
   "metadata": {},
   "source": [
    "### 2.3 Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a602133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102292"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removind duplicates (over 7k)\n",
    "print(FEVER_df.shape[0])\n",
    "FEVER_df = FEVER_df.drop_duplicates(subset='claim', keep='first')\n",
    "FEVER_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef42f2e",
   "metadata": {},
   "source": [
    "### 2.4 Claim Length \n",
    "- Group by sentence length and take some % of each group into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e04a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEVER_df['claim_count'] = FEVER_df['claim'].str.len()\n",
    "\n",
    "# Showing claim length distribution\n",
    "fig = px.histogram(FEVER_df, x='claim_count')\n",
    "fig.update_layout(bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5af7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 different ranges of characters length that split the dataset into 8 groups: \n",
      "\n",
      " [(57.0, 68.0], (29.0, 35.0], (68.0, 614.0], (50.0, 57.0], (35.0, 40.0], (40.0, 45.0], (45.0, 50.0], (10.999, 29.0]]\n",
      "Categories (8, interval[float64]): [(10.999, 29.0] < (29.0, 35.0] < (35.0, 40.0] < (40.0, 45.0] < (45.0, 50.0] < (50.0, 57.0] < (57.0, 68.0] < (68.0, 614.0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"8 different ranges of characters length that split the dataset into 8 groups: \\n\\n\", \n",
    "      pd.qcut(FEVER_df['claim_count'], 8).unique())\n",
    "\n",
    "FEVER_df['char_category'] = pd.qcut(FEVER_df['claim_count'], 8, labels=[0, 1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cf9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 random entries from each category will be chosen \n",
    "\n",
    "dfs = []\n",
    "for category in [0, 1, 2, 3, 4, 5, 6, 7]:\n",
    "    category_df_false = FEVER_df[(FEVER_df['char_category'] == category) & (FEVER_df['claim_veracity'] == 0)]\n",
    "    category_df_true = FEVER_df[(FEVER_df['char_category'] == category) & (FEVER_df['claim_veracity'] == 1)]\n",
    "    dfs.append(category_df_true.sample(250, random_state=1)) \n",
    "    dfs.append(category_df_false.sample(250, random_state=1)) \n",
    "    \n",
    "FEVER_picked = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b5ef1",
   "metadata": {},
   "source": [
    "## 3. Saving new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56407ce7",
   "metadata": {},
   "source": [
    "### 3.1. Whole FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddd6ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEVER_df = FEVER_df.sample(frac=1).reset_index(drop=True).drop(['claim_count', 'char_category'], axis=1)\n",
    "FEVER_df.to_csv('FEVER_Final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0013d",
   "metadata": {},
   "source": [
    "### 3.2. Picked FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aea9b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEVER_picked = FEVER_picked.sample(frac=1).reset_index(drop=True).drop(['claim_count', 'char_category'], axis=1)\n",
    "FEVER_picked.to_csv('FEVER_Picked.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
