{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849df345",
   "metadata": {},
   "source": [
    "# GOOGLE SEARCH VERIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb12db",
   "metadata": {},
   "source": [
    "Google Search Verifier, given the sentence forms a query and scrapes the results from the front page of google. It then calculates Levenshtein score that measures the similarity between the initial query and the results. This is done to help with unreliable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b7ca3",
   "metadata": {},
   "source": [
    "### Necessery Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3301ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import ssl\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from leven import levenshtein\n",
    "from bs4 import BeautifulSoup\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b6f1a",
   "metadata": {},
   "source": [
    "### List of User Agents\n",
    "- Google makes it hard to scrape the results from their search engine. In order to prevent google from banning a \"bot that scrapes its results\" user-agents have to be definined to trick google into thinking that human is behind the computer\n",
    "- In each query a random user-agent is picked from this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814d99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agents = [\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.56 (KHTML, like Gecko) Chrome/87.0.4283.88 Safari/535.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.61 (KHTML, like Gecko) Chrome/87.0.4284.88 Safari/532.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_17_5) AppleWebKit/532.60 (KHTML, like Gecko) Chrome/87.0.4288.88 Safari/537.32',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_17_3) AppleWebKit/532.90 (KHTML, like Gecko) Chrome/87.0.4281.88 Safari/537.31',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.74.9 (KHTML, like Gecko) Chrome/87.0.4281.88 Safari/537.74.9'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.2526.106 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.2526.106 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3946.132 Safari/537.32'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0aa75",
   "metadata": {},
   "source": [
    "### Google Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2fcedc",
   "metadata": {},
   "source": [
    "The algorithm works as follows:\n",
    "- Get random user agents lists and a dataset of claims\n",
    "- For each row in dataset\n",
    "    - create a google query\n",
    "    - wait 5 seconds\n",
    "    - Create a request (add random user agent)\n",
    "    - Read the response\n",
    "    - Parse the results\n",
    "    - Initialise score and results to 0\n",
    "    - For each div that appear on the main page:\n",
    "        - Get the title\n",
    "        - Calculate Levenstein score between title and the query\n",
    "        - Save leven_score and increment results\n",
    "    - Save overall leven_score divided by nr of the results scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e223a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe -> dataframe that needs an attribute named \"claim\" that will be queried in google\n",
    "# waittime -> time that the algorithm waits before executing 2 queries in a row. Default = 5s\n",
    "def google_scrape(dataframe, waittime = 5):\n",
    "    for i, row in dataframe.iterrows():\n",
    "        \n",
    "        # Get the claim and form a google query\n",
    "        claim = row.tweet__text\n",
    "#         claim = row.claim\n",
    "        query = claim.replace(\" \", \"+\")\n",
    "        query = 'https://google.com/search?q=' + query\n",
    "\n",
    "        # wait \"waittime\" seconds in between each query\n",
    "        time.sleep(waittime) \n",
    "\n",
    "        # Send the request and parse results\n",
    "        request = urllib.request.Request(query)\n",
    "        request.add_header('User-agent', random.choice(user_agents))\n",
    "        raw_response = urllib.request.urlopen(request).read()\n",
    "        html = raw_response.decode(\"utf-8\")\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        divs = soup.select(\"#search div.g\")\n",
    "        \n",
    "        results = 0\n",
    "        leven_score = 0\n",
    "        # Scrape the titles that appear on the main page\n",
    "        for div in divs:\n",
    "            result = div.select(\"h3\")\n",
    "            if (len(result) >= 1):\n",
    "                title = result[0].get_text()\n",
    "                if title[-3:] == '...':\n",
    "                    title = title[:-4]\n",
    "                    \n",
    "                # Calculate levenshtein score between the initial claim and a google result (title)\n",
    "                leven_score += levenshtein(claim, title)\n",
    "                results += 1\n",
    "                \n",
    "            if results != 0:\n",
    "                dataframe.at[i,'leven__score'] = leven_score/results\n",
    "            else:\n",
    "                dataframe.at[i,'leven__score'] = -1 # omething went wrong put \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9323bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(dataframe, data_name):\n",
    "    google_scrape(dataframe, 4)\n",
    "    print(dataframe.head(5))\n",
    "    dataframe.to_csv(data_name, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11a26c",
   "metadata": {},
   "source": [
    "## Performing Google Scraping on particular datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abfa5e",
   "metadata": {},
   "source": [
    "### 1. Test\n",
    "Running code below would take ages, hence a cell to test the script is provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32b503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         tweet__text  claim_veracity  \\\n",
      "0  Beyonce faces $20M copyright suit from Youtube...               1   \n",
      "1  Site is getting blown up now thanks to Real Cl...               0   \n",
      "\n",
      "   leven__score  \n",
      "0           5.3  \n",
      "1          46.6  \n"
     ]
    }
   ],
   "source": [
    "data = [['Beyonce faces $20M copyright suit from Youtube stars estate', 1, 0], \n",
    "        ['Site is getting blown up now thanks to Real Clear Politics', 0, 0]]\n",
    "df = pd.DataFrame(data, columns = ['tweet__text', 'claim_veracity', 'leven__score'])\n",
    "\n",
    "getResults(df, 'results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627f90f",
   "metadata": {},
   "source": [
    "### 2. TwitterFakeNews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3797b",
   "metadata": {},
   "source": [
    "#### 2.1 Fake entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0dfcf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Auto_df_fake = pd.read_csv('../Datasets_analysis/TwitterFakeNews/Auto_Format_Fake.csv', \n",
    "                           sep=';', usecols = ['tweet__fake', 'tweet__text'], low_memory=False)\n",
    "\n",
    "# Add additional column leven_score\n",
    "Auto_df_fake['leven__score'] = 0.0\n",
    "getResults(Auto_df_fake, 'Auto_df_fake_score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5b9e3",
   "metadata": {},
   "source": [
    "#### 2.2 True Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f10b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto_df_true = pd.read_csv('../Datasets_analysis/TwitterFakeNews/Auto_Format_True.csv', sep=';', \n",
    "                           usecols = ['tweet__fake', 'tweet__text'], low_memory=False)\n",
    "\n",
    "# Add additional column leven_score\n",
    "Auto_df_true['leven__score'] = 0.0\n",
    "getResults(Auto_df_true, 'Auto_df_true_score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54660ffa",
   "metadata": {},
   "source": [
    "### 3. LIAR Half-True entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIAR_half_true_df = pd.read_csv('../Datasets_analysis/LIAR/LIAR_half_true.csv', \n",
    "                                usecols = ['claim_veracity', 'claim'], low_memory=False)\n",
    "\n",
    "# Add additional column leven_score\n",
    "LIAR_half_true_df['leven__score'] = 0.0\n",
    "getResults(LIAR_half_true_df, 'LIAR_half_true_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
